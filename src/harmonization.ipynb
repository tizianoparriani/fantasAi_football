{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://github.com/maladeep/Name-Matching-In-Python/blob/master/Surprisingly%20Effective%20Way%20To%20Name%20Matching%20In%20Python.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from dynaconf import LazySettings\n",
    "from dynaconf.utils.boxing import DynaBox\n",
    "from scipy.sparse import csr_matrix\n",
    "from typing import List\n",
    "import sparse_dot_topn.sparse_dot_topn as ct  #Cosine Similarity\n",
    "import time\n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/tiziano/workspaces/fantasAi_football/config/conf.yaml\"\n",
    "config_mode = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ingestion_basics(params: DynaBox, table: str, duplicate_key_err:str='raise') -> pd.DataFrame:\n",
    "    \"\"\"Performs some basic harmonization steps on a input dataframe.\n",
    "\n",
    "    Note that after the basic harmonization the columns will have the names\n",
    "    stated in settings.COLS, and not those appearing in the input data.\n",
    "\n",
    "    Args:\n",
    "        table (pd.DataFrame): id of the table to lead, it must appear in\n",
    "            config file\n",
    "        duplicate_key_err ('raise' or 'drop'): how to handle duplicated key\n",
    "        errors. If 'raise' an error will be return in case of duplicated keys,\n",
    "        if 'drop' all duplicated rows will be dropped from data.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If table registry dataframe keys are missing\n",
    "        KeyError: If table registry dataframe keys are duplicated\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe in input, harmonized\n",
    "    \"\"\"\n",
    "    # Load parameters\n",
    "    t_par = params[table]\n",
    "    t_cols_dict = t_par[\"COLS\"].to_dict()\n",
    "    keys: List[str] = [t_par[\"COLS\"][c] for c in t_par.KEY]\n",
    "    cols: List[str] = list(t_cols_dict.values())\n",
    "    dtype_map = {\n",
    "        c_name: params[\"FEATURES\"][\"DTYPES\"][c]\n",
    "        for c, c_name in t_cols_dict.items()\n",
    "    }\n",
    "    name_conversion = {\n",
    "        c_from: params[\"FEATURES\"][c] for c, c_from in t_cols_dict.items()\n",
    "    }\n",
    "    \n",
    "    path = os.path.join(\n",
    "        params[\"PATHS\"][\"ROOT_FOLDER\"], \n",
    "        params[\"PATHS\"][\"INPUT\"][\"FOLDER\"],\n",
    "         params[\"PATHS\"][\"INPUT\"][table]\n",
    "    )\n",
    "    data: pd.DataFrame = pd.read_csv(path)\n",
    "\n",
    "    # Keep only selected columns\n",
    "    data = data[cols]\n",
    "\n",
    "    # Ugly but functional call to ensure correct type conversion\n",
    "    data = data.convert_dtypes().astype(dtype_map, errors='ignore').convert_dtypes()  # type: ignore\n",
    "\n",
    "    # Ensure that the product registry dataframe keys are valid\n",
    "    if not data[keys].notna().all(axis=1).all():\n",
    "        raise ValueError(f\"{table} dataframe keys are missing\")\n",
    "    if not data.value_counts(keys).eq(1).all():\n",
    "        if duplicate_key_err == 'raise':\n",
    "            raise KeyError(f\"{table} keys are duplicated\")\n",
    "        else:\n",
    "            print(f\"WARN: dupliated keys will be removed from {table}\")\n",
    "            data = data.drop_duplicates(subset=keys, keep=False)\n",
    "\n",
    "    # Sort product product registry by DIVISION,PRODUCT and reset index\n",
    "    data = data.sort_values(keys).reset_index(drop=True)\n",
    "\n",
    "    data = data.rename(columns=name_conversion)\n",
    "\n",
    "    if \"FILTER\" in params:\n",
    "        if table in params[\"FILTER\"]:\n",
    "            for column, values in params[\"FILTER\"].get(table).to_dict().items():\n",
    "                column_name = params[\"FEATURES\"].get(column)\n",
    "                data = data.loc[data[column_name].isin(values)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = LazySettings(settings_files=[config_file])\n",
    "params = params[config_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: dupliated keys will be removed from VOTES_ITA\n"
     ]
    }
   ],
   "source": [
    "players = data_ingestion_basics(params, \"PLAYERS\")\n",
    "votes_ita = data_ingestion_basics(params, \"VOTES_ITA\", duplicate_key_err='drop')\n",
    "\n",
    "players['date_of_birth'] = pd.to_datetime(players['date_of_birth'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=3):\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.concat(\n",
    "    [players[params[\"FEATURES\"][\"NAME\"]], \n",
    "    votes_ita[params[\"FEATURES\"][\"PIANETAFANTA_NAME\"]]],\n",
    "    ignore_index=True\n",
    "    )\n",
    "names = names.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# After having each words split (token or  lemmas (n-gram generated items) ) into a vector and\n",
    "# Scikit-learnâ€™s  Tfidfvectorizer aim to do the same thing, which is to convert a collection of raw documents to a matrix of TF-IDF features. \n",
    "# Generate the matrix of TF-IDF (Term Frequency-Inverse Document frequency)values for each\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "vectorizer = vectorizer.fit(names)\n",
    "tm_names = vectorizer.transform(players[params[\"FEATURES\"][\"NAME\"]]) \n",
    "pf_names = vectorizer.transform(votes_ita[params[\"FEATURES\"][\"PIANETAFANTA_NAME\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7193)\t0.7498043525871992\n",
      "  (0, 597)\t0.6616596049641319\n"
     ]
    }
   ],
   "source": [
    "# View sparse CSR matrix.\n",
    "print(pf_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the similarity between two vectors of TF-IDF values the Cosine Similarity is usually used.\n",
    "# result matrix in a very sparse terms and Scikit-learn deals with this nicely by returning a sparse CSR matrix.\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELFTIMED: 0.009179353713989258\n"
     ]
    }
   ],
   "source": [
    "#  Run the optimized cosine similarity function. \n",
    "#  Only stores the top 10 most similar items with a similarity above 0.8\n",
    "\n",
    "t1 = time.time()\n",
    "matches = awesome_cossim_top(\n",
    "    tm_names, \n",
    "    pf_names.transpose(),\n",
    "    10,\n",
    "    0.8\n",
    "    )\n",
    "t = time.time() - t1\n",
    "print(\"SELFTIMED:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacks the resulting sparse matrix\n",
    "\n",
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                          'right_side': right_side,\n",
    "                           'similairity': similairity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 67 is out of bounds for axis 0 with size 67",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb#ch0000015vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# store the  matches into new dataframe called matched_df and printing 10 samples\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb#ch0000015vscode-remote?line=2'>3</a>\u001b[0m matches_df \u001b[39m=\u001b[39m get_matches_df(matches, names, top\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb#ch0000015vscode-remote?line=3'>4</a>\u001b[0m matches_df \u001b[39m=\u001b[39m matches_df[matches_df[\u001b[39m'\u001b[39m\u001b[39msimilairity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m0.99999\u001b[39m]\n",
      "\u001b[1;32m/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb Cell 12'\u001b[0m in \u001b[0;36mget_matches_df\u001b[0;34m(sparse_matrix, name_vector, top)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb#ch0000013vscode-remote?line=15'>16</a>\u001b[0m similairity \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(nr_matches)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb#ch0000013vscode-remote?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, nr_matches\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb#ch0000013vscode-remote?line=18'>19</a>\u001b[0m     left_side[index] \u001b[39m=\u001b[39m name_vector[sparserows[index]]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb#ch0000013vscode-remote?line=19'>20</a>\u001b[0m     right_side[index] \u001b[39m=\u001b[39m name_vector[sparsecols[index]]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/tiziano/workspaces/fantasAi_football/src/harmonization.ipynb#ch0000013vscode-remote?line=20'>21</a>\u001b[0m     similairity[index] \u001b[39m=\u001b[39m sparse_matrix\u001b[39m.\u001b[39mdata[index]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 67 is out of bounds for axis 0 with size 67"
     ]
    }
   ],
   "source": [
    "# store the  matches into new dataframe called matched_df and printing 10 samples\n",
    "\n",
    "matches_df = get_matches_df(matches, names, top=200)\n",
    "matches_df = matches_df[matches_df['similairity'] < 0.99999] # For removing all exact matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_side</th>\n",
       "      <th>right_side</th>\n",
       "      <th>similairity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Douglas</td>\n",
       "      <td>Douglao</td>\n",
       "      <td>0.848212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Mario Fernandes</td>\n",
       "      <td>Mario Fernandez</td>\n",
       "      <td>0.882370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Wellington</td>\n",
       "      <td>Wellington Nem</td>\n",
       "      <td>0.819218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Wellington</td>\n",
       "      <td>Wellington Luis</td>\n",
       "      <td>0.814134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Lyle Taylor</td>\n",
       "      <td>Kyle Taylor</td>\n",
       "      <td>0.820820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Andre</td>\n",
       "      <td>Andre Andre</td>\n",
       "      <td>0.849399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Chris Maxwell</td>\n",
       "      <td>Maxwell</td>\n",
       "      <td>0.812869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           left_side       right_side  similairity\n",
       "38           Douglas          Douglao     0.848212\n",
       "88   Mario Fernandes  Mario Fernandez     0.882370\n",
       "102       Wellington   Wellington Nem     0.819218\n",
       "103       Wellington  Wellington Luis     0.814134\n",
       "161      Lyle Taylor      Kyle Taylor     0.820820\n",
       "165            Andre      Andre Andre     0.849399\n",
       "178    Chris Maxwell          Maxwell     0.812869"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_side</th>\n",
       "      <th>right_side</th>\n",
       "      <th>similairity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Mario Fernandes</td>\n",
       "      <td>Mario Fernandez</td>\n",
       "      <td>0.882370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Andre</td>\n",
       "      <td>Andre Andre</td>\n",
       "      <td>0.849399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Douglas</td>\n",
       "      <td>Douglao</td>\n",
       "      <td>0.848212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Lyle Taylor</td>\n",
       "      <td>Kyle Taylor</td>\n",
       "      <td>0.820820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Wellington</td>\n",
       "      <td>Wellington Nem</td>\n",
       "      <td>0.819218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Wellington</td>\n",
       "      <td>Wellington Luis</td>\n",
       "      <td>0.814134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Chris Maxwell</td>\n",
       "      <td>Maxwell</td>\n",
       "      <td>0.812869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           left_side       right_side  similairity\n",
       "88   Mario Fernandes  Mario Fernandez     0.882370\n",
       "165            Andre      Andre Andre     0.849399\n",
       "38           Douglas          Douglao     0.848212\n",
       "161      Lyle Taylor      Kyle Taylor     0.820820\n",
       "102       Wellington   Wellington Nem     0.819218\n",
       "103       Wellington  Wellington Luis     0.814134\n",
       "178    Chris Maxwell          Maxwell     0.812869"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df.sort_values(['similairity'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7954512d69f46d5250bf9304f32c886eecc79deaa42271adec6a58e91c41ee7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fantasai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
